{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kuzushiji Classification with Support Vector Machines\n",
    "\n",
    "In this notebook we are going to explore the use of Support Vector Machines (SVM) for image classification. We will use a variant of the famous MNIST dataset (the original is a dataset of handwritten digits). The version we are going to use is called Kuzushiji-MNIST or K-MNIST for short (https://github.com/rois-codh/kmnist) and is a dataset of traditional japanese handwritten kana.\n",
    "\n",
    "\n",
    "\n",
    "The dataset labels are the following:\n",
    "\n",
    "| Label | Hiragana Character | Romanji (Pronunciation) |\n",
    "| :-: | :-: | :-: |\n",
    "|   0   | お | o |\n",
    "| 1 | き | ki |\n",
    "| 2 | す | su |\n",
    "| 3 | つ | tsu |\n",
    "| 4 | な | na |\n",
    "| 5 | は | ha |\n",
    "| 6 | ま | ma |\n",
    "| 7 | や | ya |\n",
    "| 8 | れ | re |\n",
    "| 9 | を | wo |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Insert your surname, name and ID number\n",
    "\n",
    "Student surname: Cappelli\n",
    "\n",
    "Student name: Pietro\n",
    "    \n",
    "ID: 2058332"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the required packages\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to load Kuzushiji-MNIST dataset\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "    labels_path = os.path.join(path, 'K%s-labels-idx1-ubyte.gz' % kind)\n",
    "    images_path = os.path.join(path, 'K%s-images-idx3-ubyte.gz' % kind)\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,offset=8)\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,offset=16).reshape(len(labels), 784)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix your ID (\"numero di matricola\") and the seed for random generator (as usual you can try different seeds)\n",
    "ID = 2058332\n",
    "np.random.seed(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n"
     ]
    }
   ],
   "source": [
    "#load the K-MNIST dataset from the 'data' folder and let's normalize the features so that each value is in [0,1] \n",
    "\n",
    "X, y = load_mnist('data', kind='train')\n",
    "# rescale the data\n",
    "X, y = X / 255., y # original pixel values are between 0 and 255\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split into training and test. Make sure that each label is present at least 10 times\n",
    "in training. If it is not, then keep adding permutations to the initial data until this \n",
    "happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in training dataset:  [0 1 2 3 4 5 6 7 8 9]\n",
      "Frequencies in training dataset:  [62 64 55 57 56 59 57 54 73 63]\n",
      "(600,)\n"
     ]
    }
   ],
   "source": [
    "# Random permute the data and split into training and test taking the first 600\n",
    "# data samples as training and 4000 samples as test\n",
    "permutation = np.random.permutation(X.shape[0])\n",
    "\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 600\n",
    "m_test = 4000\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:m_training+m_test:]\n",
    "y_train, y_test = y[:m_training], y[m_training:m_training+m_test:]\n",
    "\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for plotting a image and printing the corresponding label\n",
    "def plot_input(X_matrix, labels, index):\n",
    "    print(\"INPUT:\")\n",
    "    plt.imshow(\n",
    "        X_matrix[index].reshape(28,28),\n",
    "        cmap          = plt.cm.gray_r,\n",
    "        interpolation = \"nearest\"\n",
    "    )\n",
    "    plt.show()\n",
    "    print(\"LABEL: %i\"%labels[index])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's try the plotting function\n",
    "# plot_input(X_train,y_train,5)\n",
    "# plot_input(X_test,y_test,50)\n",
    "# plot_input(X_test,y_test,500)\n",
    "# plot_input(X_test,y_test,700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 1\n",
    "Use a SVM classifier with cross validation to pick a model. Use a 4-fold cross-validation. Let's start with a Linear kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LINEAR KERNEL\n",
      "Best parameters set found:\n",
      "{'C': 0.1}\n",
      "best estimator found: SVC(C=0.1, class_weight='balanced', kernel='linear')\n",
      "Score with best parameters:\n",
      "0.7383333333333333\n",
      "All scores on the grid:\n",
      "[0.735      0.73833333 0.735      0.735     ]\n"
     ]
    }
   ],
   "source": [
    "#import SVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "#import for Cross-Validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters for linear SVM\n",
    "parameters = {\"C\": [0.01, 0.1, 1, 10]}\n",
    "\n",
    "#train linear SVM\n",
    "linear = SVC(kernel='linear', class_weight='balanced')\n",
    "# linear.fit(X_train,y_train)\n",
    "# print(linear.n_support_)\n",
    "\n",
    "clf= GridSearchCV(linear, parameters, cv=4)\n",
    "clf.fit(X_train,y_train)\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print('best estimator found:',clf.best_estimator_)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "print ('RESULTS FOR LINEAR KERNEL')\n",
    "print(\"Best parameters set found:\")\n",
    "print(clf.best_params_)\n",
    "print('best estimator found:',clf.best_estimator_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "print(clf.best_score_)\n",
    "\n",
    "print(\"All scores on the grid:\")\n",
    "print(clf.cv_results_[\"mean_test_score\"])\n",
    "lin_score = clf.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 2\n",
    "Pick a model for the Polynomial kernel with degree=2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR POLY DEGREE=2 KERNEL\n",
      "Best parameters set found:\n",
      "{'C': 0.1, 'gamma': 0.1}\n",
      "Score with best parameters:\n",
      "0.765\n",
      "\n",
      "All scores on the grid:\n",
      "[0.12166667 0.74833333 0.75833333 0.41666667 0.765      0.75833333\n",
      " 0.74833333 0.75833333 0.75833333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88       425\n",
      "           1       0.65      0.80      0.72       377\n",
      "           2       0.71      0.61      0.65       429\n",
      "           3       0.83      0.84      0.84       391\n",
      "           4       0.76      0.68      0.72       386\n",
      "           5       0.89      0.80      0.84       419\n",
      "           6       0.65      0.69      0.67       390\n",
      "           7       0.94      0.82      0.88       377\n",
      "           8       0.72      0.85      0.78       411\n",
      "           9       0.79      0.81      0.80       395\n",
      "\n",
      "    accuracy                           0.78      4000\n",
      "   macro avg       0.78      0.78      0.78      4000\n",
      "weighted avg       0.78      0.78      0.78      4000\n",
      "\n",
      "best estimator found: SVC(C=0.1, degree=2, gamma=0.1, kernel='poly')\n"
     ]
    }
   ],
   "source": [
    "# parameters for poly with degree 2 kernel\n",
    "parameterss = {'C': [0.01, 0.1, 1],'gamma':[0.01,0.1,1]}\n",
    "\n",
    "#run SVM with poly of degree 2 kernel\n",
    "svpoly2 = SVC(kernel='poly', degree=2)\n",
    "\n",
    "clf2= GridSearchCV(svpoly2, parameterss, cv=4)\n",
    "clf2.fit(X_train,y_train)\n",
    "ypoly2_pred = clf2.predict(X_test)\n",
    "print ('RESULTS FOR POLY DEGREE=2 KERNEL')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "# ADD YOUR CODE\n",
    "print(clf2.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "# ADD YOUR CODE\n",
    "print(clf2.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "print(clf2.cv_results_[\"mean_test_score\"])\n",
    "\n",
    "print(classification_report(y_test, ypoly2_pred))\n",
    "print('best estimator found:',clf2.best_estimator_)\n",
    "\n",
    "poly2_score = clf2.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 3\n",
    "\n",
    "Now let's try a higher degree for the polynomial kernel (e.g., 3rd degree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR POLY DEGREE= 5  KERNEL\n",
      "Best parameters set found:\n",
      "{'C': 1, 'gamma': 0.01}\n",
      "Score with best parameters:\n",
      "0.6233333333333333\n",
      "\n",
      "All scores on the grid:\n",
      "[0.12333333 0.59333333 0.58833333 0.26666667 0.58833333 0.58833333\n",
      " 0.62333333 0.58833333 0.58833333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.74      0.82       425\n",
      "           1       0.31      0.88      0.46       377\n",
      "           2       0.60      0.63      0.61       429\n",
      "           3       0.93      0.58      0.72       391\n",
      "           4       0.78      0.56      0.65       386\n",
      "           5       0.86      0.68      0.76       419\n",
      "           6       0.81      0.46      0.58       390\n",
      "           7       0.93      0.68      0.79       377\n",
      "           8       0.69      0.81      0.75       411\n",
      "           9       0.84      0.64      0.73       395\n",
      "\n",
      "    accuracy                           0.67      4000\n",
      "   macro avg       0.77      0.67      0.69      4000\n",
      "weighted avg       0.77      0.67      0.69      4000\n",
      "\n",
      "best estimator found: SVC(C=1, degree=4, gamma=0.01, kernel='poly')\n"
     ]
    }
   ],
   "source": [
    "# parameters for poly with higher degree kernel\n",
    "parameters = {'C': [0.01, 0.1, 1],'gamma':[0.01,0.1,1]}\n",
    "\n",
    "#run SVM with poly of higher degree kernel\n",
    "degree = 5\n",
    "\n",
    "svpoly3 = SVC(kernel='poly', degree=4)\n",
    "\n",
    "clf3= GridSearchCV(svpoly3, parameters, cv=4)\n",
    "clf3.fit(X_train,y_train)\n",
    "ypoly3_pred = clf3.predict(X_test)\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print ('RESULTS FOR POLY DEGREE=', degree, ' KERNEL')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "# ADD YOUR CODE\n",
    "print(clf3.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "# ADD YOUR CODE\n",
    "print(clf3.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "# ADD YOUR CODE\n",
    "print(clf3.cv_results_[\"mean_test_score\"])\n",
    "\n",
    "print(classification_report(y_test, ypoly3_pred))\n",
    "print('best estimator found:',clf3.best_estimator_)\n",
    "\n",
    "poly3_score = clf3.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 4\n",
    "Pick a model for the Radial Basis Function kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR rbf KERNEL\n",
      "Best parameters set found:\n",
      "{'C': 10, 'gamma': 0.01}\n",
      "Score with best parameters:\n",
      "0.795\n",
      "\n",
      "All scores on the grid:\n",
      "[0.12166667 0.16666667 0.12166667 0.12166667 0.58       0.78\n",
      " 0.12833333 0.12166667 0.75       0.795      0.135      0.12166667\n",
      " 0.75666667 0.795      0.135      0.12166667]\n"
     ]
    }
   ],
   "source": [
    "# parameters for rbf SVM\n",
    "parameters = {'C': [0.1, 1, 10, 100],'gamma':[0.001, 0.01, 0.1,1]}\n",
    "\n",
    "#run SVM with rbf kernel\n",
    "\n",
    "rbf = SVC(kernel='rbf')\n",
    "clf_rbf= GridSearchCV(rbf, parameters, cv=4)\n",
    "clf_rbf.fit(X_train,y_train)\n",
    "yrbf_pred = clf_rbf.predict(X_test)\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print ('RESULTS FOR rbf KERNEL')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "# ADD YOUR CODE\n",
    "print(clf_rbf.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "print(clf_rbf.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "# ADD YOUR CODE\n",
    "print(clf_rbf.cv_results_[\"mean_test_score\"])\n",
    "\n",
    "rbf_score = clf_rbf.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 1\n",
    "What do you observe when using linear, polynomial and RBF kernels on this dataset ?\n",
    "\n",
    "\n",
    "The score with the best parameters is similar between the two polinomial kernel and also with the linear one. Between this scores the smaller is always the score with the linear kernel. Then there is an increasing of the values with the degree of the kernel's polinomial. However, the bigger remains the score with rbf kernel (\\tilde 0.8). We aspected this result since we can expand the rbs kernel formula with an infinite sum of polinomials of increasing degree. We choose rbf kernel as the best kernel for this analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best score of the linear kernel is 0.7383333333333333\n",
      "the best score of the poly2 kernel is 0.765\n",
      "the best score of the poly3 kernel is 0.6233333333333333\n",
      "the best score of the rbf kernel is 0.795\n"
     ]
    }
   ],
   "source": [
    "kernel=[\"linear\", \"poly2\", \"poly3\", \"rbf\"]\n",
    "best_scores = [lin_score, poly2_score, poly3_score, rbf_score]\n",
    "for i in range(4):\n",
    "    print(f'the best score of the {kernel[i]} kernel is {best_scores[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 5\n",
    "Report here the best SVM kernel and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM training error: 0.000000\n",
      "Best SVM test error: 0.186500\n"
     ]
    }
   ],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "best_SVM = SVC(kernel='rbf', C=10, gamma=0.01)\n",
    "# ADD YOUR CODE\n",
    "best_SVM.fit(X_train,y_train)\n",
    "y_pred = best_SVM.predict(X_test)\n",
    "# (error is 1 - svm.score)\n",
    "training_error = 1 - best_SVM.score(X_train,y_train)\n",
    "test_error = 1 - best_SVM.score(X_test,y_test)\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 6\n",
    "\n",
    "Analyze how the gamma parameter (inversely proportional to standard deviation of Gaussian Kernel) impact the performances of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.e-05 1.e-04 1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]\n"
     ]
    }
   ],
   "source": [
    "#Test with different values of gamma\n",
    "\n",
    "# Set gamma values\n",
    "gamma_values = np.logspace(-5,2,8)\n",
    "print(gamma_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try the SVM with the previously set values of gamma\n",
    "# use rbf kernel and C=1\n",
    "\n",
    "train_acc_list, test_acc_list = [], []\n",
    "\n",
    "    \n",
    "# ADD YOUR CODE TO TRAIN THE SVM MULTIPLE TIMES WITH THE DIFFERENT VALUES OF GAMMA\n",
    "# PLACE THE TRAIN AND TEST ACCURACY FOR EACH TEST IN THE TRAIN AND TEST ACCURACY LISTS\n",
    "\n",
    "for i in gamma_values:\n",
    "    svm = SVC(kernel='rbf', C=1, gamma=i)\n",
    "    svm.fit(X_train,y_train)\n",
    "    train_acc_list.append(svm.score(X_train,y_train))\n",
    "    test_acc_list.append(svm.score(X_test,y_test))\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "ax[0].plot(gamma_values, train_acc_list)\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_xlabel('gamma')\n",
    "ax[0].set_ylabel('Train accuracy')\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(gamma_values, test_acc_list)\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_xlabel('gamma')\n",
    "ax[1].set_ylabel('Test accuracy')\n",
    "ax[1].grid(True)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 2\n",
    "How do the train and test error change when changing gamma ? Which is the best value of gamma ? \n",
    "Connect your answers to the discussion about the overfitting issue.\n",
    "\n",
    "This two graphic show the accuracy on the train and test set.\n",
    "About train accuracy, the curve reach the maximum for values of gamma >= 0.1. However, looking at the test accuracy, the best value is when gamma is 0.01. So the best gamma is set on 0.01 since is the best value in common between the two accuracy. \n",
    "From the test accuracy graphic we can note that we have an overfitting issue since at value of gamma=0.1 or 1 (corresponding to the optimal solution of train acc.) the test acc decrease on values of \\tilde 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More data\n",
    "Now let's do the same but using more data points for training.\n",
    "\n",
    "\n",
    "Choose a new number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in training dataset:  [0 1 2 3 4 5 6 7 8 9]\n",
      "Frequencies in training dataset:  [196 181 210 196 226 176 190 214 225 186]\n"
     ]
    }
   ],
   "source": [
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 2000 # TODO number of data points, adjust depending on the capabilities of your PC\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 7\n",
    "\n",
    "Let's try to use SVM with parameters obtained from the best model for $m_{training} =  2000$. Since it may take a long time to run, you can decide to just let it run for some time and stop it if it does not complete. If you decide to do this, report it in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "best_SVM = SVC(kernel='rbf', C=10, gamma=0.01)\n",
    "best_SVM.fit(X_train,y_train)\n",
    "# (error is 1 - svm.score)\n",
    "training_error = 1 - best_SVM.score(X_train,y_train)\n",
    "test_error = 1 - best_SVM.score(X_test,y_test)\n",
    "\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for comparison, let's also use logistic regression \n",
    "\n",
    "## TO DO 8 Try first without regularization (use a very large large C)¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# ADD YOUR CODE\n",
    "lgr = linear_model.LogisticRegression(C=1e15, max_iter=1000)\n",
    "lgr.fit(X_train,y_train)\n",
    "\n",
    "training_error = 1 - lgr.score(X_train,y_train)\n",
    "test_error = 1 - lgr.score(X_test,y_test)\n",
    "\n",
    "print (\"Best logistic regression training error: %f\" % training_error)\n",
    "print (\"Best logistic regression test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 9 Try  with regularization (use C=1)¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE\n",
    "lgr2 = linear_model.LogisticRegression(C=1, max_iter=1000)\n",
    "lgr2.fit(X_train,y_train)\n",
    "\n",
    "training_error = 1 - lgr2.score(X_train,y_train)\n",
    "test_error = 1 - lgr2.score(X_test,y_test)\n",
    "\n",
    "print (\"Best regularized logistic regression training error: %f\" % training_error)\n",
    "print (\"Best regularized logistic regression test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 3\n",
    "Compare and discuss:\n",
    "- the results from SVM with m=600 and with m=2000 training data points. If you stopped the SVM, include such aspect in your comparison.\n",
    "- the results of SVM and of Logistic Regression\n",
    "\n",
    "a) Following there are show the results of the test error with m=600,2000 training data point:\n",
    "- m=600   => test error = 0.186500 \n",
    "- m=2000  => test error = 0.114362\n",
    "\n",
    "As expected, the test error using a larger training set is better. This result is expected because the machine is \"more trained\" so it has more accuracy on predicting the data.\n",
    "\n",
    "b) the test error with Logistic regression are 0.29 without regolarization and 0.25 with reg. Both of them are worst than the result with SVM (0.11)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 10\n",
    "Plot an item of clothing that is missclassified by logistic regression and correctly classified by SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_SVM = SVC(kernel='rbf', C=10, gamma=0.01)\n",
    "best_SVM.fit(X_train,y_train)\n",
    "\n",
    "lgr2 = linear_model.LogisticRegression(C=1, max_iter=1000)\n",
    "lgr2.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "LR_prediction = lgr2.predict(X_test)\n",
    "SVM_prediction = best_SVM.predict(X_test)\n",
    "\n",
    "# ADD CODE\n",
    "LR_misclass, SVM_misclass = [], []\n",
    "lista = []\n",
    "\n",
    "print(LR_prediction)\n",
    "print(SVM_prediction)\n",
    "print(y_test)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if(LR_prediction[i] != y_test[i] and SVM_prediction[i] == y_test[i]):\n",
    "        lista.append(i)\n",
    "i=0\n",
    "flag=True\n",
    "# while(flag==True and i<len(y_test)):\n",
    "#     if(LR_prediction[i] != y_test[i] and SVM_prediction[i] == y_test[i]):\n",
    "#         plot_input(X_test,y_test,i)\n",
    "#         flag=False\n",
    "#     i+=1\n",
    "    \n",
    "# print(lista)\n",
    "plot_input(X_test, y_test, lista[0])\n",
    "#invece che printare il 0 potrei fare printare uno scelto random\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 11\n",
    "Plot the confusion matrix for the SVM classifier and for logistic regression.\n",
    "The confusion matrix has one column for each predicted label and one row for each true label. \n",
    "It shows for each class in the corresponding row how many samples belonging to that class gets each possible output label.\n",
    "Notice that the diagonal contains the correctly classified samples, while the other cells correspond to errors.\n",
    "You can obtain it with the sklearn.metrics.confusion_matrix function (see the documentation).\n",
    "Try also to normalize the confusion matrix by the number of samples in each class in order to measure the accuracy on each single class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, suppress=True) # for better aligned printing of confusion matrix use floatmode='fixed'\n",
    "\n",
    "LR_prediction = lgr2.predict(X_test)\n",
    "SVM_prediction = best_SVM.predict(X_test)\n",
    "u, counts = np.unique(y_test, return_counts=True)\n",
    "print(\"Labels and frequencies in test set: \", counts)\n",
    "\n",
    "confusion_SVM = skm.confusion_matrix(y_test, SVM_prediction)\n",
    "print(\"\\n Confusion matrix SVM  \\n \\n\", confusion_SVM)\n",
    "print(\"\\n Confusion matrix SVM (normalized)   \\n \\n\", confusion_SVM /counts[:,None] )\n",
    "\n",
    "confusion_LR =  skm.confusion_matrix(y_test, LR_prediction)\n",
    "print(\"\\n Confusion matrix LR  \\n \\n\", confusion_LR)\n",
    "print(\"\\n Confusion matrix LR (normalized)   \\n \\n\", confusion_LR /counts[:,None] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD CODE TO NORMALIZE CONFUSION MATRIX AND PRINT THE NORMALIZED MATRIX\n",
    "confusion_SVM_norm = skm.confusion_matrix(y_test, SVM_prediction, normalize='true')\n",
    "print(\"\\n Confusion matrix SVM  \\n \\n\", confusion_SVM_norm)\n",
    "\n",
    "confusion_LR_norm =  skm.confusion_matrix(y_test, LR_prediction, normalize='true')\n",
    "print(\"\\n Confusion matrix LR  \\n \\n\", confusion_LR_norm)\n",
    "\n",
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "# plot_confusion_matrix(best_SVM, X_test, y_test, normalize='true')\n",
    "# plt.show()\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# disp = ConfusionMatrixDisplay.from_estimator(best_SVM, X_test, y_test, display_labels=labels, cmap=plt.cm.Blues, normalize=\"true\")\n",
    "# print(disp.confusion_matrix)\n",
    "# plt.show()\n",
    "\n",
    "# disp1 = ConfusionMatrixDisplay(confusion_matrix=cm1, display_labels=best_SVM.classes_)\n",
    "# disp2 = ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels=best_SVM.classes_)\n",
    "\n",
    "# disp1.plot()\n",
    "# disp2.plot()\n",
    "\n",
    "A = ConfusionMatrixDisplay(confusion_matrix=confusion_SVM, display_labels=best_SVM.classes_).plot()\n",
    "ConfusionMatrixDisplay(confusion_matrix=confusion_SVM_norm, display_labels=best_SVM.classes_).plot()\n",
    "ConfusionMatrixDisplay(confusion_matrix=confusion_LR, display_labels=best_SVM.classes_).plot()\n",
    "ConfusionMatrixDisplay(confusion_matrix=confusion_LR_norm, display_labels=best_SVM.classes_).plot()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]=5,5\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 4\n",
    "Have a look at the confusion matrices and comment on the obtained accuracies. Why some classes have lower accuracies and others an higher one ? Make some guesses on the possible causes.\n",
    "\n",
    "\n",
    "In the confusion matrix we can visualize the accuracy of the algorithm in predicting the test set. In particularly we can see what label the machine predict for the samples. Obviously the entries of the diagonal are bigger than the other since they represent how many sample are correcly classified. However there are some entries out of the diagonal which are bigger than the other. For example, (2,6) or (3,5) or (6,2). It may depends on how similar are the japanese letters from the machine's point of view and so it (or she) confuses, for example, the sixth letter with the second.\n",
    "\n",
    "PS: In the last plot the color help to visualize the concept explained in the answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
